min_distance <- min(dist_df)
max_distance <- max(dist_df)
dist_df_normalized <- ((dist_df - min_distance) / (max_distance - min_distance) - 0.5) * 2  # Normalize to [-1, 1]
# Convert normalized distances to similarities
similarity_df <- 1 - dist_df_normalized  # Similarity: closer items have higher values
# Display the normalized similarity matrix
similarity_df
# Plot the reordered similarity matrix
corrplot(as.matrix(similarity_df_ordered),
method = "color",
tl.col = "black",
is.corr = FALSE,  # This is not a correlation matrix
title = "Similarity Matrix for Items (Ordered)",
addgrid.col = "darkgray")
similarity_df
dist_df_normalized
# Plot the reordered similarity matrix
corrplot(as.matrix(dist_df_normalized),
method = "color",
tl.col = "black",
is.corr = FALSE,  # This is not a correlation matrix
title = "Similarity Matrix for Items (Ordered)",
addgrid.col = "darkgray")
desired_order <- c("see something", "hear something", "choose what to do",
"remember something", "think about something", "reach for something",
"sit down", "jump up and down", "kick something", "take a walk",
"get tired", "become hungry", "feel scared", "experience pain", "get sick")
##
min_distance <- min(dist_df)
max_distance <- max(dist_df)
dist_df_normalized <- ((dist_df - min_distance) / (max_distance - min_distance) - 0.5) * 2  # Normalize to [-1, 1]
# Convert normalized distances to similarities
similarity_df <- dist_df_normalized  # Similarity: closer items have higher values
similarity_df_ordered <- similarity_df[desired_order, desired_order]
similarity_df_ordered
# Plot the reordered similarity matrix
corrplot(as.matrix(similarity_df_ordered),
method = "color",
tl.col = "black",
is.corr = FALSE,  # This is not a correlation matrix
title = "Similarity Matrix for Items (Ordered)",
addgrid.col = "darkgray")
df
df %>%
group_by(items) %>%
mutate(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df
df %>%
group_by(items) %>%
mutate(x = mean(x_m, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
mutate(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
summarize(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE)) %>%
ungroup()
df %>%
group_by(items) %>%
summarize(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
mutate(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE)) %>%
ungroup()
df %>%
group_by(items) %>%
mutate(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
summarize(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
mutate(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE))
df %>%
select(itemA:item_pair_means)
directory_path <- here("code", "analysis", "pilot", "data-slider")
file_paths <- list.files(path = directory_path, full.names = TRUE)
d <- map_df(file_paths, ~ read_csv(.x) %>% mutate(filename = basename(.x)))
# retain relevant columns
df <- d %>%
relocate(mturk_participant_id, .before = "trial_id") %>%
select("mturk_participant_id", "trial_id", "rt", "response",
"itemA", "itemB", "categoryA", "categoryB") %>%
filter(!trial_id %in% c("practice_feedback", "demographics_survey",
"consent", "practice_round")) %>%
mutate(response = as.numeric(response)) %>%
filter(!str_detect(trial_id, "^attention_check_")) %>%
mutate(type = ifelse(categoryA == categoryB, "within domain", "across domain")) %>%
mutate(categoryA = case_when(categoryA == "physiological" ~ "bio",
categoryA == "cognitive" ~ "cog",
TRUE ~ "act"),
categoryB = case_when(categoryB == "physiological" ~ "bio",
categoryB == "cognitive" ~ "cog",
TRUE ~ "act")) %>%
mutate(category_pairs = str_c(categoryA, categoryB, sep = "-"))  %>%
group_by(category_pairs) %>%
mutate(category_pair_means = mean(response)) %>% #reordering category labels
ungroup() %>%
mutate(category_pairs = fct_reorder(category_pairs,
category_pair_means, .desc = TRUE)) %>%
mutate(item_pairs = str_c(itemA, itemB, sep = "-")) %>%
group_by(item_pairs) %>%
mutate(item_pair_means = round(mean(response), 0))# %>%
df %>%
select(itemA:item_pair_means)
df %>%
select(itemA:item_pair_means) %>%
unique()
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items:y_mean)
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup()
d <- map_df(file_paths, ~ read_csv(.x) %>% mutate(filename = basename(.x)))
d
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location)  # Expand parsed JSON
directory_path <- here("code", "analysis", "pilot", "data-freesort")
file_paths <- list.files(path = directory_path, full.names = TRUE)
d <- map_df(file_paths, ~ read_csv(.x) %>% mutate(filename = basename(.x)))
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location)  # Expand parsed JSON
items <- c("choose what to do", "reach for something", "feel scared",
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
df <- df %>%
mutate(img_number = as.numeric(str_extract(src, "\\d+")),
items = items[img_number]) %>%
select(-c("final_locations", "src"))
df_mean_locations <- df %>%
group_by(items) %>%
summarize(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE)) %>%
ungroup()
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup()
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items:y_mean)
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items:y_mean) %>%
unique()
##=======================
df_means <- df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items:y_mean) %>%
unique() %>%
mutate(mean_centered = (item_pair_means/100 - .5)*2)
df %>%
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items:y_mean) %>%
unique()
df %>%
# Group and calculate mean coordinates for each item
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items, x_mean, y_mean) %>%
unique()
df %>%
# Group and calculate mean coordinates for each item
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items, x_mean, y_mean) %>%
unique() %>%  # Keep only unique rows (one per item)
# Compute pairwise Euclidean distances
mutate(key = 1)
df %>%
# Group and calculate mean coordinates for each item
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items, x_mean, y_mean) %>%
unique() %>%  # Keep only unique rows (one per item)
# Compute pairwise Euclidean distances
mutate(key = 1) %>%  # Temporary key to allow full join with itself
full_join(., ., by = "key", suffix = c("_1", "_2"))
df %>%
# Group and calculate mean coordinates for each item
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items, x_mean, y_mean) %>%
unique() %>%  # Keep only unique rows (one per item)
# Compute pairwise Euclidean distances
mutate(key = 1) %>%  # Temporary key to allow full join with itself
full_join(., ., by = "key", suffix = c("_1", "_2")) %>%  # Self join
filter(items_1 != items_2)
df %>%
# Group and calculate mean coordinates for each item
group_by(items) %>%
mutate(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup() %>%
select(items, x_mean, y_mean) %>%
unique() %>%  # Keep only unique rows (one per item)
# Compute pairwise Euclidean distances
mutate(key = 1) %>%  # Temporary key to allow full join with itself
full_join(., ., by = "key", suffix = c("_1", "_2")) %>%  # Self join
filter(items_1 != items_2) %>%  # Remove self-pairs
mutate(euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2))
# Step 1: Calculate mean coordinates for each item
df_means <- df %>%
group_by(items) %>%
summarize(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup()
expand.grid(item1 = df_means$items, item2 = df_means$items)
# Step 1: Calculate mean coordinates for each item
df_means <- df %>%
group_by(items) %>%
summarize(x_mean = mean(x, na.rm = TRUE), y_mean = mean(y, na.rm = TRUE)) %>%
ungroup()
df_means
df_pairs
# Create all combinations of items
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items)
df_pairs
df_pairs
df_means
df_pairs %>%
left_join(df_means, by = c("item1" = "items"))
df_pairs %>%
left_join(df_means, by = c("item1" = "items")) %>%
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2"))
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location)  # Expand parsed JSON
items <- c("choose what to do", "reach for something", "feel scared",
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
df <- df %>%
mutate(img_number = as.numeric(str_extract(src, "\\d+")),
items = items[img_number]) %>%
select(-c("final_locations", "src"))
df
df_pairs
# Merge coordinates for each pair
df_pairs <- df_pairs %>%
left_join(df_means, by = c("item1" = "items")) %>%
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2"))
df_pairs
df_pairs %>%
filter(item1 != item2)
# Calculate Euclidean distance for each pair
df_pairs <- df_pairs %>%
filter(item1 != item2) %>%  # Remove self-pairs
mutate(euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2)) %>%
select(item1, item2, euclidean_distance)
df_pairs
expand.grid(item1 = df_means$items, item2 = df_means$items) %>%
left_join(df_means, by = c("item1" = "items")) %>%
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),     # Calculate Euclidean distance
normalized_distance = ((euclidean_distance - min(euclidean_distance)) /
(max(euclidean_distance) - min(euclidean_distance)) - 0.5) * 2     # Normalize to the range [-1, 1]
) %>%
select(item1, item2, euclidean_distance, normalized_distance)
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),     # Calculate Euclidean distance
normalized_distance = ((euclidean_distance - min(euclidean_distance)) /
(max(euclidean_distance) - min(euclidean_distance)) - 0.5) * 2     # Normalize to the range [-1, 1]
) %>%
select(item1, item2, euclidean_distance, normalized_distance)
df_pairs
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location)  # Expand parsed JSON
items <- c("choose what to do", "reach for something", "feel scared",
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
df <- df %>%
mutate(img_number = as.numeric(str_extract(src, "\\d+")),
items = items[img_number]) %>%
select(-c("final_locations", "src"))
items <- c("choose what to do", "reach for something", "feel scared",
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
items <- c("choose what to do", "reach for something", "feel scared",
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location) %>% # Expand parsed JSON
mutate(img_number = as.numeric(str_extract(src, "\\d+")), #attach items
items = items[img_number]) %>%
select(-c("final_locations", "src"))
df
items <- c("choose what to do", "reach for something", "feel scared",  #items in exact order of img1.png to img15.png
"experience pain", "get sick", "get tired", "become hungry",
"see something", "think about something", "hear something",
"remember something", "jump up and down", "kick something",
"take a walk", "sit down")
df <- d %>%
relocate(mturk_participant_id, .before = "success") %>%
select(mturk_participant_id, trial_type, rt, final_locations) %>%
filter(trial_type == "free-sort") %>%
mutate(parsed_location = map(final_locations, fromJSON)) %>% #extract data saved as json
unnest(parsed_location) %>% # Expand parsed JSON
mutate(img_number = as.numeric(str_extract(src, "\\d+")), #attach items
items = items[img_number]) %>%
select(-c("final_locations", "src"))
desired_order <- c("see something", "hear something", "choose what to do",
"remember something", "think about something", "reach for something",
"sit down", "jump up and down", "kick something", "take a walk",
"get tired", "become hungry", "feel scared", "experience pain", "get sick")
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),     # Calculate Euclidean distance
normalized_distance = ((euclidean_distance - min(euclidean_distance)) /
(max(euclidean_distance) - min(euclidean_distance)) - 0.5) * 2     # Normalize to the range [-1, 1]
) %>%
select(item1, item2, euclidean_distance, normalized_distance)
df_pairs
df_pairs %>%
select(item1, item2, normalized_distance) %>%
pivot_wider(names_from = item2, values_from = normalized_distance) %>%
column_to_rownames("item1")
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),     # Calculate Euclidean distance
normalized_distance = ((euclidean_distance - min(euclidean_distance)) /
(max(euclidean_distance) - min(euclidean_distance)) - 0.5) * 2     # Normalize to the range [-1, 1]
) %>%
select(item1, item2, normalized_distance) %>%
pivot_wider(names_from = item2, values_from = normalized_distance) %>%
column_to_rownames("item1")  # Convert `item1` to row names
# Step 3: Plot with corrplot
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Normalized Similarity Matrix",
addgrid.col = "darkgray")
# Step 1: Pivot the data to wide format
dist_matrix <- df_pairs %>%
select(item1, item2, normalized_distance) %>%
pivot_wider(names_from = item2, values_from = normalized_distance) %>%
column_to_rownames("item1")  # Convert `item1` to row names
# Step 2: Convert to a matrix
dist_matrix <- as.matrix(df_pairs)
# Step 3: Plot with corrplot
corrplot(dist_matrix, method = "color", is.corr = FALSE,
tl.col = "black", title = "Normalized Similarity Matrix",
addgrid.col = "darkgray")
df_pairs <- df_pairs[desired_order, desired_order] #reorder
df_pairs
corrplot(df_pairs, method = "color", is.corr = FALSE,
tl.col = "black", title = "Normalized Similarity Matrix (Ordered)",
addgrid.col = "darkgray")
df_pairs
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Normalized Similarity Matrix (Ordered)",
addgrid.col = "darkgray")
df_pairs
diag(df_pairs) <- 0 #set diagonals to 0
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Normalized Similarity Matrix (Ordered)",
addgrid.col = "darkgray")
par(mar = c(5, 4, 4, 2) + 0.1)
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(5, 4, 4, 2) + 0.1)
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(5, 4, 4, 2) + 0.1)
par(mar = c(1, 1, 5, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 1, 9, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 1, 20, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 1, 10, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 1=5, 10, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 5, 10, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 20, 10, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
par(mar = c(1, 20, 5, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),
normalized_distance = ((euclidean_distance - min(euclidean_distance)) /
(max(euclidean_distance) - min(euclidean_distance)) - 0.5) * 2, #normalize to -1,1
similarity_score = 1 - normalized_distance
) %>%
select(item1, item2, similarity_score) %>%
pivot_wider(names_from = item2, values_from = similarity_score) %>%
column_to_rownames("item1")  # Convert `item1` to row names
df_pairs <- df_pairs[desired_order, desired_order] #reorder
diag(df_pairs) <- 0 #set diagonals to 0
par(mar = c(1, 20, 5, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
df_pairs <- expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),
similarity_score = 1 / (1 + euclidean_distance),
normalized_similarity = ((similarity_score - min(similarity_score)) /
(max(similarity_score) - min(similarity_score)) - 0.5) * 2
) %>%
select(item1, item2, normalized_similarity) %>%
pivot_wider(names_from = item2, values_from = normalized_similarity) %>%
column_to_rownames("item1")  # Convert `item1` to row names
df_pairs <- df_pairs[desired_order, desired_order] #reorder
diag(df_pairs) <- 0 #set diagonals to 0
diag(df_pairs) <- 0 #set diagonals to 0
par(mar = c(1, 20, 5, 1))  # Increase the top margin (third value) to give more space for the title
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
expand.grid(item1 = df_means$items, item2 = df_means$items) %>% #create all combinations of items
left_join(df_means, by = c("item1" = "items")) %>% #merge coordinates for each pair
left_join(df_means, by = c("item2" = "items"), suffix = c("_1", "_2")) %>%
filter(item1 != item2) %>%
mutate(
euclidean_distance = sqrt((x_mean_1 - x_mean_2)^2 + (y_mean_1 - y_mean_2)^2),
similarity_score = 1 / (1 + euclidean_distance),
normalized_similarity = ((similarity_score - min(similarity_score)) /
(max(similarity_score) - min(similarity_score)) - 0.5) * 2
)
diag(df_pairs) <- 1 #set diagonals to 0
corrplot(as.matrix(df_pairs), method = "color", is.corr = FALSE,
tl.col = "black", title = "Similarity Matrix- - Freesort",
addgrid.col = "darkgray")
